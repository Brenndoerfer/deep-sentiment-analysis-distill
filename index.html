<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">


    <title>Deep Sentiment Analysis - Distill Literature Review</title>

    <!-- Bootstrap core CSS -->
    <link href="https://fonts.googleapis.com/css?family=Gentium+Book+Basic" rel="stylesheet">
    <link href="css/rnn.css" rel="stylesheet">
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g=" crossorigin="anonymous"></script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script src="js/seqinput.js"></script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
    });












    </script>
    <style type="text/css">
        p {
            font-family: 'Gentium Book Basic', serif;
            font-size: 20px;
            text-align: justify;
        }

        .fig {
            margin: 25px auto 50px auto;
        }

        .cap {
            margin: 0 auto;
        }

        h2 {
            margin-top: 50px;
        }

        h3 {
            margin-top: 20px;
            font-size: 24px;
        }
    </style>
    <script type="text/javascript">

        //        $(document).ready(function () {
        //            $(".fig").hover(function () {
        //                $(this).css("background-color", "pink");
        //            }, function () {
        //                $(this).css("background-color", "transparent");
        //            });
        //        })
        //        ;

    </script>

</head>

<style>
    #slidecontainer {
        width: 100%;
    }

    .slider {
        -webkit-appearance: none;
        width: 100%;
        height: 25px;
        background: #d3d3d3;
        outline: none;
        opacity: 0.7;
        -webkit-transition: .2s;
        transition: opacity .2s;
    }

    .slider:hover {
        opacity: 1;
    }

    .slider::-webkit-slider-thumb {
        -webkit-appearance: none;
        appearance: none;
        width: 25px;
        height: 25px;
        background: #4CAF50;
        cursor: pointer;
    }

    .slider::-moz-range-thumb {
        width: 25px;
        height: 25px;
        background: #4CAF50;
        cursor: pointer;
    }
</style>

<body style="background-color: #eee">
<div class="container" style="background-color: #fff; padding: 100px 150px;">
    <div class="row">
        <div class="col-lg-12">
            <img src="img/ucb.png" height="50" style="float:right; margin-top: -50px;"/>
            <center><h1>Deep Sentiment Analysis</h1>
                <b>Michael Brenndoerfer*, Stefan Palombo*, Vinitra Swamy*</b><br>
                    UC Berkeley Electrical Engineering and Computer Sciences (EECS)<br>
                    Distill Literature Review <br>
                    <font size="-1">*equal contribution, alphabetical order </font></center>
            <hr style="margin: 50px 0">

            <h2>Introduction</h2>
            <p>The research endeavor of sentiment analysis boils down to a simple question: How can a computer read a book? More specifically, how can a computer understand what it’s reading in terms of sentiment? </p>
            <p>Sentiment analysis aims to understand people’s opinions, sentiments, attitudes, and emotions from written language or speech (Liu, 2012). It is widely applied on data which contains customer opin- ions. The objective is,
                to process the data and extract the general attitude of the author towards a certain topic. Let’s consider some examples:
                A very simple example would be “This soap is amazing” or “Yack. That’s disguisting!”, or more complex phrases such as “The strawberries where delicious, although they we</p>

            <h3>Road Map</h3>
            <p>Our review begins with describing the problem space of NLP with this very general question. We then introduce deep sentiment analysis as an area of research inquiry that takes advantage of the recent leaps in computing from
                Neural Networks and deep learning to solve this problem. We dive into various approaches to address deep sentiment analysis, splitting our article into three main areas: the many ways to represent text data (Featurization) and recent techniques in deep learning to procure sentiment-related insights (LSTMs and CNNs). </p>

            <h2>Featurization</h2>
            <h3>Encoding Representations</h3>
            <p>In the research area of Deep Sentiment analysis, we start with a text file with nothing but words, and we know there is latent structure and meaning in their representation. We know that the ordering of words matters, the use of punctuation can convey strong feelings, and perhaps most importantly, word choice reveals a lot about sentiment. We also know that some words have positive or negative connotations with different levels of severity, and that words are related to each other in complex ways. How do we encode the plain text file that we recieve as relevant inputs to a deep learning model? NLP has created a variety of approaches to solve this problem.</p>
            <ul>
                <li><b>bag-of-words</b>: This approach only keeps the counts of each time each word appears, disregarding the grammar and order of the input data. It makes the strong assumption that words are independent of each other, and that word frequencies reveal everything we need to know about content. While this seems like we're losing a lot of information, this approach performs remarkably well as a baseline.</li><br>
                <li><b>TF-IDF</b>: This acronym expands to "Term Frequency - Inverse Document Frequency" and is an expansion on traditional bag-of-words approaches. TF-IDF reflects “importance” of a word in a corpus by creating a metric that's based on the name -- the frequency of the word appearing over the total number of times it's mentioned across all documents.</li><br>
                <li><b>n-gram encoding</b>: This is another expansion of bag-of-words, but considers more than one word at a time. If n=1, we have the same thing as the bag-of-words approach. If n=2, we're considering combinations of two words as a unique term in our document. For example, consider the sentence "Vinitra, Michael, and Stefan went to the park." ["Vinitra", "Michael"] would be a bigram, ["Michael", "and"] would be another bigram, and so on. </li><br>
                <li><b>stop word removal</b>: This is an addendum to previous techniques mentioned above, and involves removing words that theoretically don't hold much meaning (i.e. "the", "an", "and", etc.). This provides the advantage of reducing the number of unique words in your data, and therefore the dimensionality of your vocabulary. However, the disadvantage here (although not super relevant to the problem of sentiment analysis) is that you might lose some relevant information about author style. The number of quotation marks and stopwords can be used to predict time period of writing / gender of author / other descriptive metadata. </li><br>
            </ul>

            <h3>Word Embeddings</h3>
            <p>After determining the many ways to generate unique terms for our model, we result
            <p>Word embeddings are vector generated to represent words, usually trained using neural networks. This boosts performance for sentiment analysis immensely. Word2Vec is a Google package that uses 2-layer NNs and the skip-gram /
                CBOW algorithms to train embeddings.</p>

            <p> For the default example, train the network by training the model for 500 iterations (pressing the green "500" button) and observing the relationship between "woman" and "queen" and "man" and "king". Then perform Principal
                Component Analysis by pressing the "PCA" button. (This is just a way to reduce dimensions of our data and display them in relation to each other).</p>
            <div hidden class="alert alert-danger" id="error"></div>
            <div class="row mt-5">
                <div class="col-sm-8 no-padding">
                    <div class="panel panel-default">
                        <center>
                            <div class="panel-heading"><b>Neurons</b></div>
                            <div class="panel-body">
                                <div id="neuron-vis"></div>
                                <div>
                                    <div class="mb-2"><b>Training iterations</b></div>
                                    <div class="btn-group">
                                        <button class="btn btn-success" id="btn-next">Next</button>
                                        <button class="btn btn-success" id="btn-next20">20</button>
                                        <button class="btn btn-success" id="btn-next100">100</button>
                                        <button class="btn btn-success" id="btn-next500">500</button>
                                        <button class="btn btn-success" id="btn-pca">PCA</button>
                                    </div>
                                    <br>
                                    <br>
                                    <button class="btn btn-primary" id="btn-restart">Update and Restart</button>
                                    <button class="btn btn-primary" id="btn-learning-rate">Update Learning Rate</button>
                                    <br>
                                    <br>
                                </div>
                            </div>
                        </center>
                    </div>
                </div>  <!-- end of top left-panel -->

                <div class="col-sm-4 no-padding mt-3">
                    <div class="panel panel-default">
                        <div class="panel-heading"><b>Control Panel</b></div>
                        <small>These are the visualization inputs! You can change the input data in "Training Data"
                            and the number of hidden layers/learning rate in configurations.
                        </small>
                        <div class="panel-body mt-4">
                            <div>
                                <div><b>Neural Network Configurations</b></div>
                                <textarea rows="4" cols="50" style="font-size: 10px" id="config-text"></textarea>
                                <br>
                            </div>
                            <div class="mt-3">
                                <div><b>Training data (context|target)</b></div>
                                <textarea r rows="4" cols="50" style="font-size: 10px" id="input-text"></textarea>
                                <br>
                            </div>
                            <div class="mt-3">
                                <b>Presets</b>
                                <select id="sel-presets"></select>
                                <br>
                            </div>
                        </div>
                    </div>
                </div> <!-- end of top left-panel -->

            </div>  <!-- end of top row-->
            <hr>
            <div class="row">
                <div class="col-sm-6 no-padding">
                    <div class="panel panel-default">
                        <center>
                            <div class="panel-heading">Weight Matrices</div>
                        </center>
                        <div class="panel-body">
                            <div id="heatmap-vis"></div>
                        </div>
                    </div>
                </div>  <!-- end of lower left panel-->
                <div class="col-sm-6 no-padding">
                    <div class="panel panel-default">
                        <center>
                            <div class="panel-heading">Vectors</div>
                        </center>
                        <div class="panel-body">
                            <div id="scatterplot-vis"></div>
                        </div>
                    </div>
                </div>  <!-- end of lower-right panel-->
            </div>  <!-- end of bottom row -->
            <br>
            <center>
                <small>Figure 1: Interactive Word Embedding Visualization</small>
                <br>
                <small>Based on UMichigan's Word Embedding Visual Inspector by ronxin</small>
            </center>
        </div>  <!-- end of container -->
        <script src="js/jquery-2.1.3.min.js"></script>
        <script src="js/bootstrap.min.js"></script>
        <script src="js/d3.v3.min.js"></script>
        <script src="js/assert.js"></script>
        <script src="js/pca.js"></script>
        <script src="js/vector_math.js"></script>
        <script src="js/toyw2v.js"></script>
        <div class="text-center fig">
          <img id="tensorboard_gif" src="img/tensorboard_projector.gif"/>
          <small>Figure 2: Word Embedding Space visualization using Tensorflow Projector</small>
        </div>

        <h3 class="mt-5">Tensor-Related Models After Word2Vec (Maas et. al, Mikolov et. al)</h3>
        <p>Maas presents a model that features metrics for semantic similarity and word sentiment on the IMDB dataset, and Mikolov presents a mathematical representation of skip-gram and bag-of-words models in a continuous space. </p>

        
        <h2>Recurrent Neural Nets</h2>
        <p>In the previous section we learned about word embeddings, and that this technique allows us to have a vector-based representation of words, which is able to capture the complex syntax and semantics of a language. Also, we know
            that classical Artificial Neural Networks (ANN) perform operations on vectors and matrices. So, how can we leverage this knowledge for sentiment analysis tasks?</p>
        <h3>Input sequences are sentence based</h3>
        <p>In fact, sentences are just a sequence of words, and sentiment analysis is basically the task of classifying certain sequences of words as certain types of sentiment. Thus, we need to use a technique that allows us to process a
            sequence based input and assign a specific class. The solution is Recurrent Neural Networks (RNN). We will assume that you know what a regular, fully-connected feed-forward neural network is, and how it works. </p>
        <p>Classical neural networks are feed-forward networks that have inputs, potentially multiple hidden layers, and outputs. Such a feed-forward network can only take a certain window of words into consideration, whereas “recurrent
            neural networks can take into account all of the predecessor words” (Sundermeyer). This works because with RNNs, each element of the input sequence is assigned to a specific timestep of the RNN. This sequential approach
            allows the network to capture the temporal aspect of the input sequence. Figure 1 depicts the structure of an sequential input. </p>

        <div class="col-lg-12">
            <div class="text-center fig col-lg-10">
                <div class="seq-input">
                    <h3>Example input sequence</h3>
                    <div class="input-group mb-4">
                  <span class="input-group-btn">
                    <button class="btn btn-secondary" type="button">Input sequence</button>
                  </span>
                        <input type="text" class="form-control" placeholder="Sentence ..." id="in-sentence" style="min-width: 400px">
                    </div>
                    <div class="seq-output">

                    </div>
                </div>
            </div>
        </div>
        <div class="text-center fig">
            <small>Figure 3: Structure of an input sequence</small>
        </div>

        <p>All the words in the sequence are highly dependent on each other. As depicted in Figure 1, every word is an input at a specific timestep of the sequence, and every timestep has a hidden state $h_t$ that tries to encode the
            previously-seen information. Additionally, at every timestep a weight matrix $W^X$, which is different for every timestep, gets multiplied with the current input $x_t$, where $x_t$ represents the current encoded word. $W^H$ is a
            recurrent weight matrix. This basically means that it stays the same, from the input to the output, but the weights still get updated at every timestep. The goal of $W^H$ is to encapsulate all information across all timesteps.
            The final hidden state is then fed into a softmax function, which gives a predicted class. The weight matrices within the RNN "are updated through an optimization process called backpropagation through time (Deshpande, 2017)."</p>

        <h3>States and structure of RNNs</h3>
        <p>Given the formula used to compute the hidden state $h_t$ at every timestep $t$, we can identify two problems considering different value settings. For example, when $W^H$ has big values, and $W^X$ has small ones, $h_t$
            is going to be significantly impacted by $H_{(t-1)}$. Non mathematically speaking, the current hidden state vector is not very dependent on the previous step. In the context of an input sequence of words, the current word would
            have no significant relationship to/ contextual dependence on the previous one.</p>

        <div class="row mt-5">
            <div class="col-lg-12 text-center ml-5 rnn">
            </div>
        </div>
    </div>

    <div class="text-center fig">
        <small>Figure 4: Visualization of an RNN given Figure 3's input</small>
    </div>

    <p>Thinking about the above-described situation and considering how backpropagation works (weights are updated based on the gradients of the error with respect to the current weight (Hecht-Nielsen1989)), we can identify two
        problems. If elements early in the sequence cause the value of the hidden state to become too big, this is going to over-saturate the gradient. This is known as the exploding gradient problem, in which the elements will have an
        unproportionally high importance. The same thing can occur when a gradient is very small and converges to zero during backpropagation. This then causes the cell to die, known as the vanishing gradient problem. Due to this
        vanishing and exploding gradient problem, RNNs are harder to train than NNs. This problem also exists in feed-forward networks, but impacts RNNs even more because they are basically larger and deeper feed-forward networks with a
        cycle.</p>

    <h2>Long Short-Term Memory</h2>
    <p>Long Short-Term Memory (LSTM) is a recurrent neural network (RNN) architecture and was already proposed by Hofreiter in 1997 (Hofreiter, 1997). The idea is that the hidden states of the RNN get replaced by so-called LSTM modules,
        which
        have
        four
        different gates. These gates handle the in- and output, improving the vanishing and exploding gradient problem, as well as allowing the network to "encapsulate information about long-term dependencies in the text" (Deshpande, 2017).
        The
        problem
        is that a regular RNN is not able to connect previously-occurring information to a later-occurring input. </p>

    <h3>The input, output, forget, and memory modules</h3>
    <p>As previously mentioned, the LSTM module has four components (sometimes referred to as gates), often denoted as input, output, and forget gate, as well as a memory module. The input is still denoted as $x_t$, but the LSTM
        requires $x_t$ and $h_{(t-1)}$ as input (the output of the previous state) (Gers et al, 2002). The output will be the more complexly established hidden state $h_t$. Briefly speaking, "the input gate determines how much emphasis to
        put
        on each of the
        inputs, the forget gate determines the information that we'll throw away, and the output gate determines the final $h_t$ based on the intermediate states" (Deshpande, 2017).</p>

    <div class="row mt-5 img-center">
        <div class="col-lg-12 text-center">
            <img src="img/lstm-cell.png"/>
        </div>
        <div class="col-lg-12 text-center ml-5 lstm">
        </div>
    </div>

    <div class="text-center fig">
        <small>Figure 5: Interactive visualization of an LSTM cell</small>
    </div>

    <p class="mt-5">To conclude, deep sentiment analysis using LSTMs (or RNNs) consists of taking an input sequence and determining what kind of sentiment the text has. This could be simply determining if the input is positive or negative,
        or you
        could look at it in more detail, classifying into categories, such as funny, sad, angry, excited, etc.</p>

    <h3>Additional applications or LSTMs</h3>
    <p>Additionally, LSTMs can be used for a variety of other tasks. They proved themselves useful in Language Modeling (Sundermeyer et al.), in Machine Translation (Sutskever et al., 2014), for image captioning (image to text) (Vinyals et
        al., 2015) as
        well
        as video to text (Venugopalan et al., 2015), for handwriting generation (Graves, 2014), for image generation (Gregor et al., 2015) or question answering systems (Wang and Nyberg, 2015).</p>

<h2>Convolutional Neural Nets (CNN's)</h2>
          <h3>Review of Convolutional Neural Nets</h3>
          <p>Convolutional neural networks have proven to excel on computer vision tasks. (LeCun et al., 2015, Krizhevsky et al., 2012) While CNN's are most frequently associated with computer vision and image processing tasks, work has extended CNN’s to nlp tasks. CNN’s in their most basic form consist of convolutional layers, pooling layers, and fully connected layers.</p> 

          <p>Convolutional layers relate each value of the layer's output to a local patch of the layer’s input. This is achieved by moving a filter, sometimes referred to as a kernel, across the layer's input (LeCun et al., 1998). The filter consists of a matrix. The elements of the filter are multiplied element-wise by values in a patch of either the source image or the output of a previous layer. The resulting values of this multiplication are then summed and passed through a non-linear activation function. Multiple filters can be applied to each input, this results in a notion of channels where each channel represents the results of convolution across the whole input with one filter. During training the weights of these filters are learned via back propagation.</p>  

          <p>Pooling layers perform a down-select operation on the output of convolutional layers. These pooling operations amongst other things reduce computational cost, provide a notion of simplification to layer outputs, and in the case of images, contribute slightly to rotational and positional invariance.</p> 


          <p>Depending on the task, fully connected layers are often applied after pooling and convolutional layers. In the case of sentiment analysis, these fully connected layers would likely also include layers with softmax or sigmoid activation in order to classify emotions or otherwise quantify sentiment. </p>

          <h3>Applying CNN's to sentiment analysis</h3>
          
          <p>To utilize Convolutional Neural Networks in sentiment analysis, one most both encode the semantics of source text in a vector representation and maintain the positional dependencies between words. This is usually done by utilizing some word featurization scheme followed by stacking the word embeddings in a matrix. The CNN then applies convolutional filters over these stacked word embeddings giving a notion of positional dependence  amongst  adjacent words. The first convolutional layer usual spans the entire length of a word vector and then covers a few preceeding and following embeddings. (Kim, 2014) </p>

          <p>One prevalent approach is to utilize shallow convolutional neural networks. (Kim, 2014) In these architectures, filters spanning varying numbers of words, normally 2 to 7 words, are all applied to the input. These groups of words are often referred to as n-grams where n is the number of words considered. Max pooling operations are taken over the output from applying each filter in order to extract the most important features from each filer. After the max pooling operation, a fully connected layer is applied. In this strategy, shorter filters learn short term dependencies and larger filters learn longer term dependencies. The max pooling operation then collects the information over a time horizon of a specific length and fully connected layers synthesize this information into a result. This strategy is depicted in the following gif where we apply a filter acting over 3-grams (green) and a filter acting over 5-grams (red). The words on the far left correspond to the word vectors in the input layer (in reality word vectors would be much larger than 5 dimensional)</p>

          <img id="shallow_gif" src="img/shallow.gif"/>

          <p>A more recent approach relies on deep convolutional nets. (Conneau et al., 2016) For deep convolutional approaches, character embeddings are often employed instead of word embeddings. In deep convolutional approaches, smaller filters are applied over a deep set of layers. In this strategy, subsequent layers learn dependencies amongst the features of groups of words or characters produced by previous layers much in the same way that later layers in CNN’s learn more complex features of groups of pixels in image recognition tasks. Because each layer groups features from a portion of the source text and feeds to the next layer, as one descends further into the neural net, the filters can assimilate information from greater proportions of the source text. We show this notion in the following figure. For simplicity, we display word embeddings instead of character embeddings however, one of the landmark achievements of this model structure is successful classification with character embeddings. The purple regions show the values in previous layers which contribute to the state of the purple entry on the right most layer. By moving the sliders it is possible to see how the filter size changes which inputs later layers are computed from.</p>


          <p>Drag the slider to change the number of rows in the first and second filters.</p>
          <div id="slidecontainer">
            <input type="range" min="1" max="5" value="3" class="slider" id="firstFilter">
            <p>Rows in filter for the first layer: <span id="numRow1"></span></p>
          </div>

          <div id="slidecontainer2">
            <input type="range" min="1" max="3" value="2" class="slider" id="secFilter">
            <p>Rows in filter for the second layer: <span id="numRow2"></span></p>
          </div>
          <img id="img" src="img/conv_interact/32.jpg"/>
          <script>
          var slider1 = document.getElementById("firstFilter");
          var slider2 = document.getElementById("secFilter");
          var rows1 = document.getElementById("numRow1");
          var rows2 = document.getElementById("numRow2");
          var slide1val = slider1.value;
          var slide2val = slider2.value;
          rows1.innerHTML = slider1.value;
          rows2.innerHTML = slider2.value;

          function test(s1val, s2val){
            rows1.innerHTML = slider1.value;
            rows2.innerHTML = slider2.value;
           document.getElementById("img").src="img/conv_interact/"+s1val+s2val+".jpg"
              
          }

          slider2.oninput = function() {
              slide2val = slider2.value
              slide1val = slider1.value
              test(slide1val, slide2val)
             
          }

          slider1.oninput = function() {
              slide2val = slider2.value
              slide1val = slider1.value
              test(slide1val, slide2val)
          }

          </script>

          <p>Even though many state of the art applications in language processing utilize LSTM’s (Yang, 2016), convolutional structures are free of many of the issues that are present in recurrent structures. CNN’s don’t need to backpropagate through a recurrent structure as do LSTM’s, this means that training on CNN’s is significantly faster than with LSTM’s. Additionally, CNN’s aren’t as prone to vanishing and exploding gradients as LSTM’s. This means that CNN's can provide a level of ease of training and exhibit speed advantages that make them an attractive option for text classification broadly and sentiment analysis specifically.</p>
    <h2>References</h2>
    <p>
        Martin Sundermeyer, Ralf Schlüter, and Hermann Ney. LSTM Neural Net- works for Language Modeling. URL https://pdfs.semanticscholar.org/f9a1/ b3850dfd837793743565a8af95973d395a4e.pdf.
    </p>
    <p>Hecht-Nielsen. Theory of the backpropagation neural network. In International Joint Conference on Neural Networks, pages 593–605 vol.1. IEEE, 1989. doi: 10.1109/IJCNN.1989.118638. URL http://ieeexplore.ieee.org/document/118638/.</p>
    <p>Adit Deshpande, Perform sentiment analysis with LSTMs, using TensorFlow, July 13 2017, URL https://www.oreilly.com/learning/perform-sentiment-analysis-with-lstms-using-tensorflow</p>
    <p>Josef Hochreiter. Untersuchungen zu dynamischen neuronalen Netzen. 1991.</p>

    <p>Felix A Gers, Nicol N Schraudolph, and Jürgen Schmidhuber. Learning Precise Timing with LSTM Recurrent Networks. Journal of Machine Learning Research, 3:115–143, 2002. URL
        http://machinelearning.wustl.edu/mlpapers/paper_files/GersSS02.pdf.
    <p>Alex Graves. Generating Sequences With Recurrent Neural Networks. 2014. URL https://arxiv. org/pdf/1308.0850v5.pdf.
    <p>Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Jimenez Rezende, and Daan Wierstra. DRAW: A Recurrent Neural Network For Image Generation. 2015. URL https://arxiv.org/pdf/ 1502.04623v2.pdf.
    <p>Hecht-Nielsen. Theory of the backpropagation neural network. In International Joint Conference on Neural Networks, pages 593–605 vol.1. IEEE, 1989. doi: 10.1109/IJCNN.1989.118638. URL http://ieeexplore.ieee.org/document/118638/.

    <p>James Hong and Michael Fang. Sentiment Analysis with Deeply Learned Distributed Repre- sentations of Variable Length Texts. 2015. URL https://cs224d.stanford.edu/reports/ HongJames.pdf.</p>
    <p>Bing Liu. Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Tech- nologies, 5(1):1–167, may 2012. ISSN 1947-4040. doi: 10.2200/S00416ED1V01Y201204HLT016. URL
        http://www.morganclaypool.com/doi/abs/10.2200/S00416ED1V01Y201204HLT016.</p>
    <p>Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to Sequence Learning with Neural Net- works. 2014. URL https://arxiv.org/pdf/1409.3215.pdf.</p>
    <p>Subhashini Venugopalan, Marcus Rohrbach, Jeff Donahue, Raymond Mooney, Trevor Darrell, and Kate Saenko. Sequence to Sequence – Video to Text. 2015. URL https://arxiv.org/pdf/ 1505.00487v3.pdf.</p>
    <p>Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. Show and Tell: A Neural Image Caption Generator. 2015. URL https://arxiv.org/pdf/1411.4555v2.pdf.</p>
    <p>Di Wang and Eric Nyberg. A Long Short-Term Memory Model for Answer Sentence Selection in Question Answering. pages 707–712, 2015. URL http://www.aclweb.org/anthology/ P15-2116.</p>
    <p>Hecht-Nielsen. Theory of the backpropagation neural network. In International Joint Conference on Neural Networks, pages 593–605 vol.1. IEEE, 1989. doi: 10.1109/IJCNN.1989.118638. URL
        http://ieeexplore.ieee.org/document/118638/.</p>
    <p>Kim, Y.. Convolutional Neural Networks for Sentence Classification, 2014. https://doi.org/10.3115/v1/D14-1181 </p>
    <p>Yann LeCun, L´eon Bottou, Yoshua Bengio, and Patrick
        Haffner. 1998. Gradient-based learning applied to
        document recognition. Proceedings of the IEEE,
        86(11):2278–2324.</p>

    <p>Y. LeCun, Y. Bengio, and G. E. Hinton. Deep learning.
        Nature, 2015.</p>
    <p>A. Krizhevsky, I. Sutskever, G. Hinton. 2012. ImageNet
    Classification with Deep Convolutional Neural
    Networks. In Proceedings of NIPS 2012.</p>
    <p>Yoshua Bengio, Rejean Ducharme, and Pascal Vincent.
    2001. A neural probabilistic language model.
    In NIPS, volume 13, pages 932–938, Vancouver,
    British Columbia, Canada.</p>
    <p>Wang, Y., Huang, M., Zhao, L., Zhu, X. (2016). Attention-based LSTM for Aspect-level Sentiment Classification. Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP), 606–615.</p>
    <p>Conneau, A., Schwenk, H., Barrault, L., Lecun, Y. (2016). Very Deep Convolutional Networks for Text Classification, (2001). https://doi.org/10.1007/s13218-012-0198-z</p>
</div>
</div>
</div>
</body>
</html>
